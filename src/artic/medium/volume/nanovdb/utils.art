// a node has 2^LOG2DIM children (in each dimension)
static LOG2DIM_VOXEL = 0:u32;
static LOG2DIM_LEAF  = 3:u32;
static LOG2DIM_LOWER = 4:u32;
static LOG2DIM_UPPER = 5:u32;

// a node has 2^LOG2CHILDREN voxels (in each dimension)
static LOG2CHILDREN_VOXEL = 0:u32;
static LOG2CHILDREN_LEAF  = LOG2DIM_LEAF;
static LOG2CHILDREN_LOWER = LOG2DIM_LOWER + LOG2DIM_LEAF;
static LOG2CHILDREN_UPPER = LOG2DIM_UPPER + LOG2CHILDREN_LOWER;

// how many potential voxels a node can contain (!= children) in each dimension
static DIM_VOXEL_U32  = 1:u32 << LOG2DIM_VOXEL;      // 2^0 = 1
static DIM_LEAF_U32   = 1:u32 << LOG2CHILDREN_LEAF;  // 2^3 = 8
static DIM_LOWER_U32  = 1:u32 << LOG2CHILDREN_LOWER; // 2^(3+4) = 2^7 = 128
static DIM_UPPER_U32  = 1:u32 << LOG2CHILDREN_UPPER; // 2^(3+4+5) = 2^12 = 4096

static DIM_VOXEL  = DIM_VOXEL_U32 as i32; // 2^0 = 1
static DIM_LEAF   = DIM_LEAF_U32  as i32;  // 2^3 = 8
static DIM_LOWER  = DIM_LOWER_U32 as i32; // 2^(3+4) = 2^7 = 128
static DIM_UPPER  = DIM_UPPER_U32 as i32; // 2^(3+4+5) = 2^12 = 4096

static MASK_LEAF  = DIM_LEAF_U32  as u64 - 1:u64; // 0[...]00000111
static MASK_LOWER = DIM_LOWER_U32 as u64 - 1:u64; // 0[...]01111111
static MASK_UPPER = DIM_UPPER_U32 as u64 - 1:u64; // 


/**
 * aligns a buffer index to the next 32B-aligned address
 */
fn @align_32(index: i32) -> i32 {
    let offset = (32 - (index % 32));
    let result = if offset == 32 { index } else { index + offset };
    
    result
}

/**
 * loads two times 32 bits out of the buffer (as i32) and combines them into a single u64
 */
fn @buffer_load_u64(buffer: DeviceBuffer, data_address: i32) -> u64 {
    let data_1 = buffer.load_i32(data_address)     as u64;
    let data_2 = buffer.load_i32(data_address + 1) as u64;
    (data_2 << 32 | data_1)
}

/**
 * Converts a buffer address (in Byte) to the Ignis Buffer ID (in 4 Bytes)
 * Equivalent to dividing by 4.
 */
fn @convert_address(address: i32) -> i32 {
    (address >> 2) // divide by 4
}

/**
 * Reads a mask out of the buffer and checks if the given bit is set to true or false
 */
fn @check_mask(buffer: DeviceBuffer, mask_address: i32, bit: i32) -> bool {
    // 32 bit word size
    //                                                        bit / 32
    let word = bitcast[u32](buffer.load_i32(convert_address(mask_address) + (bit >> 5)));
    //                   modulo
    (word & (1:u32 << ((bit as u32) & 31))) != 0
}

/**
 * Transforms indices into Open/NanoVDB root keys
 */
fn @root_indices_to_key(i: i32, j: i32, k: i32) -> u64 {
    let child_total = LOG2CHILDREN_UPPER as u64;
    (bitcast[u32](k) as u64 >> child_total) | ((bitcast[u32](j) as u64 >> child_total) << 21) | ((bitcast[u32](i) as u64 >> child_total) << 42)
}

/**
 * Returns the array index of the upper tiles in which the voxel with the given indices is stored.
 *  Every index is unique (since the entry is for a voxel) mod 4096 (since there are only 4096x4096x4096 voxels per lower internal node)
 *  => voxels (0, 0, 0) to (4095, 4095, 4095) are in one leaf etc
 */
fn @upper_indices_to_array_index(i: i32, j: i32, k: i32) -> i32 {
    let mask = MASK_UPPER;
    let log2dim_u64 = LOG2DIM_UPPER as u64; // 4 = lower internal,  5 = upper internal
    let child_total = LOG2CHILDREN_LOWER as u64; // 3 = leaf, 7 = lower internal, 12 = upper internal

    ((((bitcast[u32](i) as u64 & mask) >> child_total) << (2 * log2dim_u64)) | (((bitcast[u32](j) as u64 & mask) >> child_total) << log2dim_u64) | ((bitcast[u32](k) as u64 & mask) >> child_total)) as i32
}

/**
 * Returns the array index of the lower tiles in which the voxel with the given indices is stored.
 *  Every index is unique (since the entry is for a voxel) mod 128 (since there are only 128x128x128 voxels per lower internal node)
 *  => voxels (0, 0, 0) to (127, 127, 127) are in one leaf etc
 */
fn @lower_indices_to_array_index(i: i32, j: i32, k: i32) -> i32 {
    let mask = MASK_LOWER; // 0[...]01111111
    let log2dim_u64 = LOG2DIM_LOWER as u64; // 4 = lower internal,  5 = upper internal
    let child_total = LOG2CHILDREN_LEAF as u64; // 3 = leaf, 7 = lower internal, 12 = upper internal

    ((((bitcast[u32](i) as u64 & mask) >> child_total) << (2 * log2dim_u64)) | (((bitcast[u32](j) as u64 & mask) >> child_total) << log2dim_u64) | ((bitcast[u32](k) as u64 & mask) >> child_total)) as i32
}

/**
 * Returns the array index of the leaf tiles in which the voxel with the given indices is stored.
 *  Every index is unique (since the entry is for a voxel) mod 8 (since there are only 8x8x8 voxels per leaf)
 *  => voxels (0, 0, 0) to (7, 7, 7) are in one leaf, then (8, 8, 8) to (15, 15, 15) etc
 */
fn @leaf_indices_to_array_index(i: i32, j: i32, k: i32) -> i32 {
    let mask = MASK_LEAF; // 0[...]00111
    let log2dim_u64 = LOG2DIM_LEAF as u64;

    (((bitcast[u32](i) as u64 & mask) << (2:u64 * log2dim_u64)) | ((bitcast[u32](j) as u64 & mask) << log2dim_u64) | (bitcast[u32](k) as u64 & mask)) as i32
}

/**
 * Transforms voxel indices into their respective sparse index in a given dimension (bottom left voxel in the node)
 *  dimension: 1 = not sparse (voxel level), 8 = leaf is sparse, 128 = lower internal node is sparse, 4096 = upper internal node is sparse
 *  
 * Note: The indices in our index system are in domain [0, A+B], rather than the NanoVDB domain [-A, B].
 *  Using this method for NanoVDB requires first mapping back the indices to the NanoVDB domain.
 */
fn @general_to_sparse_index(i: i32, j: i32, k: i32, dimension: i32) -> (/* i */ i32, /* j */ i32, /* k */ i32) {
    if (dimension > DIM_UPPER) {
        return((0, 0:i32, 0:i32))
    }
    let mask = !(dimension - 1:i32);
    (i & mask, j & mask, k & mask)
}

